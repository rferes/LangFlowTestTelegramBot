{"id":"06c53c49-66f6-4f27-9ab7-0d558f785b3e","data":{"nodes":[{"id":"Webhook-iYj5F","type":"genericNode","position":{"x":-121.3145532964669,"y":-232.9517797636886},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema import Data\n\n\nclass WebhookComponent(Component):\n    display_name = \"Webhook\"\n    description = \"Defines a webhook input for the flow.\"\n    name = \"Webhook\"\n\n    inputs = [\n        MultilineInput(\n            name=\"data\",\n            display_name=\"Payload\",\n            info=\"Receives a payload from external systems via HTTP POST.\",\n        )\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\n    ]\n\n    def build_data(self) -> Data:\n        message: str | Data = \"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return Data(data={})\n        try:\n            body = json.loads(self.data or \"{}\")\n        except json.JSONDecodeError:\n            body = {\"payload\": self.data}\n            message = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n        data = Data(data=body)\n        if not message:\n            message = data\n        self.status = message\n        return data\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Payload","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Receives a payload from external systems via HTTP POST.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Defines a webhook input for the flow.","base_classes":["Data"],"display_name":"Webhook (Telegran Reciver)","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output_data","display_name":"Data","method":"build_data","value":"__UNDEFINED__","cache":true}],"field_order":["data"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false},"type":"Webhook","id":"Webhook-iYj5F"},"selected":false,"width":320,"height":234,"dragging":false,"positionAbsolute":{"x":-121.3145532964669,"y":-232.9517797636886}},{"id":"TelegramBotMessage-Zs2Wf","type":"genericNode","position":{"x":1372.7253977605783,"y":-215.2856548002028},"data":{"node":{"template":{"_type":"Component","bot_token":{"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"bot_token","value":"7581946019:AAGt34sMQyfjmfWTIocoztCQfOgk7IbYl2c","display_name":"Bot Token","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Telegram Bot API Token","title_case":false,"type":"str","_input_type":"MessageTextInput"},"chat_id":{"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"chat_id","value":"","display_name":"Chat ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Chat ID para enviar mensagem","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nimport requests\n\nclass TelegramSenderComponent(Component):\n    display_name = \"Telegram Bot Message\"\n    description = \"Send messages via Telegram Bot API\"\n    icon = \"message-square\"\n    name = \"TelegramBotMessage\"\n    inputs = [\n        MessageTextInput(\n            name=\"bot_token\",\n            display_name=\"Bot Token\",\n            info=\"Telegram Bot API Token\",\n            value=\"\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"chat_id\",\n            display_name=\"Chat ID\",\n            info=\"Chat ID para enviar mensagem\",\n            value=\"\",\n            tool_mode=True,\n        ),\n\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"Message to send via Telegram\",\n            value=\"\",\n            tool_mode=True,\n        ),\n    ]\n    outputs = [Output(display_name=\"Response\", name=\"output\", method=\"build_output\")]\n\n    def build_output(self) -> Data:\n        url = f\"https://api.telegram.org/bot{self.bot_token}/sendMessage\"\n        params = {\n            \"chat_id\": self.chat_id,\n            \"text\": self.message\n        }\n        try:\n            response = requests.get(url, params=params)\n            response.raise_for_status()\n            result = response.json()\n            data = Data(value=result)\n        except Exception as e:\n            data = Data(value=str(e))\n        self.status = data\n        return data","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"message":{"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"message","value":"","display_name":"Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to send via Telegram","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Send messages via Telegram Bot API","icon":"message-square","base_classes":["Data"],"display_name":"Telegram Sender","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Response","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["bot_token","chat_id","message"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TelegramBotMessage","id":"TelegramBotMessage-Zs2Wf"},"selected":false,"width":320,"height":407,"dragging":false},{"id":"ParseData-8yZcI","type":"genericNode","position":{"x":243.87437700866326,"y":-233.02004496398536},"data":{"node":{"template":{"_type":"Component","data":{"tool_mode":false,"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The webhook data to parse.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\nfrom typing import Tuple\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Extract message text and chat ID from Telegram webhook data.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The webhook data to parse.\"),\n    ]\n    outputs = [\n        Output(display_name=\"Chat ID\", name=\"chat_id\", method=\"get_chat_id\"),\n        Output(display_name=\"Message Text\", name=\"message\", method=\"parse_data\")\n    ]\n\n    def _process_data(self) -> Tuple[str, int]:\n        \"\"\"Helper method to process data and extract message and chat_id\"\"\"\n        data = self.data if isinstance(self.data, list) else [self.data]\n        data_dict = data[0].model_dump()\n        \n        # Extract message and chat_id\n        message = data_dict['data']['message']['text']\n        chat_id = data_dict['data']['message']['chat']['id']\n        \n        return message, chat_id\n\n    def parse_data(self) -> Message:\n        \"\"\"Extract and return the message text\"\"\"\n        try:\n            message, _ = self._process_data()\n            self.status = \"Message successfully extracted\"\n            return Message(text=str(message))\n        except Exception as e:\n            self.status = f\"Error extracting message: {str(e)}\"\n            raise ValueError(f\"Failed to extract message: {str(e)}\")\n\n    def get_chat_id(self) -> Message:\n        \"\"\"Extract and return the chat ID\"\"\"\n        try:\n            _, chat_id = self._process_data()\n            self.status = \"Chat ID successfully extracted\"\n            return Message(text=str(chat_id))\n        except Exception as e:\n            self.status = f\"Error extracting chat ID: {str(e)}\"\n            raise ValueError(f\"Failed to extract chat ID: {str(e)}\")","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Extract message text and chat ID from Telegram webhook data.","icon":"braces","base_classes":["Message"],"display_name":"Parse Telegram Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"chat_id","display_name":"Chat ID","method":"get_chat_id","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"message","display_name":"Message Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false},"type":"ParseData","id":"ParseData-8yZcI"},"selected":false,"width":320,"height":264,"dragging":false},{"id":"OpenAIModel-0IIUs","type":"genericNode","position":{"x":1011.331658822777,"y":26.21532717667492},"data":{"node":{"template":{"_type":"Component","output_parser":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"output_parser","value":"","display_name":"Output Parser","advanced":true,"input_types":["OutputParser"],"dynamic":false,"info":"The parser to use to parse the output of the model","title_case":false,"type":"other","_input_type":"HandleInput"},"api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"Additional keyword arguments to pass to the model.","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"tool_mode":false,"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o-mini","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":false,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"required_inputs":[]},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true,"required_inputs":[]}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed","output_parser"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"OpenAIModel","id":"OpenAIModel-0IIUs"},"selected":false,"width":320,"height":672},{"id":"CombineText-DPAbo","type":"genericNode","position":{"x":630.2158316055334,"y":15.247103226923286},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"delimiter":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"delimiter","value":"  Messagem: ","display_name":"Delimiter","advanced":false,"input_types":["Message"],"dynamic":false,"info":"A string used to separate the two text inputs. Defaults to a whitespace.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"text1":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"text1","value":"Please respond to the following message in a friendly and easy-to-read way directly in the Telegram chat.","display_name":"First Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The first text input to concatenate.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"text2":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"text2","value":"","display_name":"Second Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The second text input to concatenate.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Concatenate two text sources into a single text chunk using a specified delimiter.","icon":"merge","base_classes":["Message"],"display_name":"Combine Text","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"combined_text","display_name":"Combined Text","method":"combine_texts","value":"__UNDEFINED__","cache":true}],"field_order":["text1","text2","delimiter"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false},"type":"CombineText","id":"CombineText-DPAbo"},"selected":false,"width":320,"height":427,"dragging":false}],"edges":[{"source":"Webhook-iYj5F","target":"ParseData-8yZcI","sourceHandle":"{œdataTypeœ:œWebhookœ,œidœ:œWebhook-iYj5Fœ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-8yZcIœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","id":"reactflow__edge-Webhook-iYj5F{œdataTypeœ:œWebhookœ,œidœ:œWebhook-iYj5Fœ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-8yZcI{œfieldNameœ:œdataœ,œidœ:œParseData-8yZcIœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-8yZcI","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"Webhook","id":"Webhook-iYj5F","name":"output_data","output_types":["Data"]}},"selected":false,"className":"","animated":false},{"source":"ParseData-8yZcI","target":"CombineText-DPAbo","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-8yZcIœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œtext2œ,œidœ:œCombineText-DPAboœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-ParseData-8yZcI{œdataTypeœ:œParseDataœ,œidœ:œParseData-8yZcIœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-CombineText-DPAbo{œfieldNameœ:œtext2œ,œidœ:œCombineText-DPAboœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"text2","id":"CombineText-DPAbo","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-8yZcI","name":"message","output_types":["Message"]}},"selected":false,"className":"","animated":false},{"source":"ParseData-8yZcI","target":"TelegramBotMessage-Zs2Wf","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-8yZcIœ,œnameœ:œchat_idœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œchat_idœ,œidœ:œTelegramBotMessage-Zs2Wfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-ParseData-8yZcI{œdataTypeœ:œParseDataœ,œidœ:œParseData-8yZcIœ,œnameœ:œchat_idœ,œoutput_typesœ:[œMessageœ]}-TelegramBotMessage-Zs2Wf{œfieldNameœ:œchat_idœ,œidœ:œTelegramBotMessage-Zs2Wfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"chat_id","id":"TelegramBotMessage-Zs2Wf","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-8yZcI","name":"chat_id","output_types":["Message"]}},"selected":false,"className":"","animated":false},{"source":"CombineText-DPAbo","target":"OpenAIModel-0IIUs","sourceHandle":"{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-DPAboœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-0IIUsœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-CombineText-DPAbo{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-DPAboœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-0IIUs{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-0IIUsœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-0IIUs","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"CombineText","id":"CombineText-DPAbo","name":"combined_text","output_types":["Message"]}},"selected":false,"className":"","animated":false},{"source":"OpenAIModel-0IIUs","target":"TelegramBotMessage-Zs2Wf","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-0IIUsœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œmessageœ,œidœ:œTelegramBotMessage-Zs2Wfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-OpenAIModel-0IIUs{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-0IIUsœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TelegramBotMessage-Zs2Wf{œfieldNameœ:œmessageœ,œidœ:œTelegramBotMessage-Zs2Wfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"message","id":"TelegramBotMessage-Zs2Wf","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-0IIUs","name":"text_output","output_types":["Message"]}},"selected":false,"className":"","animated":false}],"viewport":{"x":104.16739220670047,"y":509.7818336440411,"zoom":0.4372675599960818}},"description":"Telegram chatGPT Bot","name":"Telegram chatGPT Bot","last_tested_version":"1.1.0","endpoint_name":null,"is_component":false}